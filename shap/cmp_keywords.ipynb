{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rouge-score\n",
      "  Using cached rouge_score-0.1.2-py3-none-any.whl\n",
      "Collecting absl-py (from rouge-score)\n",
      "  Downloading absl_py-2.2.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting nltk (from rouge-score)\n",
      "  Using cached nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: numpy in c:\\repos\\cs3264 project\\.venv\\lib\\site-packages (from rouge-score) (2.2.4)\n",
      "Requirement already satisfied: six>=1.14.0 in c:\\repos\\cs3264 project\\.venv\\lib\\site-packages (from rouge-score) (1.17.0)\n",
      "Collecting click (from nltk->rouge-score)\n",
      "  Using cached click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: joblib in c:\\repos\\cs3264 project\\.venv\\lib\\site-packages (from nltk->rouge-score) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\repos\\cs3264 project\\.venv\\lib\\site-packages (from nltk->rouge-score) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in c:\\repos\\cs3264 project\\.venv\\lib\\site-packages (from nltk->rouge-score) (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\repos\\cs3264 project\\.venv\\lib\\site-packages (from click->nltk->rouge-score) (0.4.6)\n",
      "Downloading absl_py-2.2.2-py3-none-any.whl (135 kB)\n",
      "Using cached nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "Using cached click-8.1.8-py3-none-any.whl (98 kB)\n",
      "Installing collected packages: click, absl-py, nltk, rouge-score\n",
      "Successfully installed absl-py-2.2.2 click-8.1.8 nltk-3.9.1 rouge-score-0.1.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install rouge-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append statement and label column to keywords\n",
    "test_df = pd.read_csv(\"../data/liar_test.csv\")\n",
    "keywords_df = pd.read_csv(\"./keywords/shap-keywords.csv\")\n",
    "new_df = pd.DataFrame()\n",
    "\n",
    "new_df[\"statement\"] = test_df[\"statement\"]\n",
    "new_df[\"label\"] = test_df[\"label\"]\n",
    "new_df[\"label\"] = new_df[\"label\"].apply(lambda x: 1 if x in [0,1,2,3] else 0)\n",
    "keywords_df = pd.concat([new_df, keywords_df], axis=1)\n",
    "keywords_df.to_csv(\"./keywords/shap-keywords.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean keywords dataset to ignore statements with \"UNKNOWN\" label generated by in-context learning\n",
    "\n",
    "# For zero-shot\n",
    "keywords_df = pd.read_csv(\"./keywords/shap-keywords.csv\")\n",
    "zero_shot_df = pd.read_csv(\"../data/results_zero-shot_v2.csv\")\n",
    "filtered_df = keywords_df[keywords_df[\"statement\"].isin(zero_shot_df[\"Claim\"])]\n",
    "filtered_df.to_csv(\"./keywords/filtered_for_zero_shot.csv\", index=False)\n",
    "\n",
    "# For few-shot\n",
    "keywords_df = pd.read_csv(\"./keywords/shap-keywords.csv\")\n",
    "few_shot_df = pd.read_csv(\"../data/results_few-shot_v2.csv\")\n",
    "filtered_df = keywords_df[keywords_df[\"statement\"].isin(few_shot_df[\"Claim\"])]\n",
    "filtered_df.to_csv(\"./keywords/filtered_for_few_shot.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For zero-shot\n",
    "zero_shot_df = pd.read_csv(\"../data/results_zero-shot_v2.csv\")\n",
    "keywords_df = pd.read_csv(\"./keywords/filtered_for_zero_shot.csv\")\n",
    "keywords_df[\"keywords_from_icl\"] = zero_shot_df[\"Keywords\"].fillna(\"\").astype(str)\n",
    "keywords_df.to_csv(\"./keywords/filtered_for_zero_shot.csv\", index=False)\n",
    "\n",
    "# For few-shot\n",
    "few_shot_df = pd.read_csv(\"../data/results_few-shot_v2.csv\")\n",
    "keywords_df = pd.read_csv(\"./keywords/filtered_for_few_shot.csv\")\n",
    "keywords_df[\"keywords_from_icl\"] = few_shot_df[\"Keywords\"].fillna(\"\").astype(str)\n",
    "keywords_df.to_csv(\"./keywords/filtered_for_few_shot.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rouge-1 Metrics\n",
    "\n",
    "R: The cat is on the mat.\n",
    "\n",
    "C: The cat and the dog.\n",
    "\n",
    "ROUGE-1 precision can be computed as the ratio of the number of unigrams in C that also appears in R, over the number of unigrams in C. ROUGE-1 precision = 3/5\n",
    "\n",
    "ROUGE-1 recall can be computed as the ratio of the number of unigrams in R that also appear in C, over the number of unigrams in R. ROUGE-1 recall = 3/6\n",
    "\n",
    "We will be using ROUGE-1 recall as our metrics for comparison, where R is the keywords generated by our binary ROBERTA classifier, and C is the key phrases generated by in-context learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-condition: zero/few_shot_df needs to have columns: keywords_from_icl, keywords_from_roberta\n",
    "\n",
    "import pandas as pd\n",
    "from rouge_score import rouge_scorer\n",
    "\n",
    "zero_shot_df = pd.read_csv(\"./keywords/filtered_for_zero_shot.csv\")\n",
    "few_shot_df = pd.read_csv(\"./keywords/filtered_for_few_shot.csv\")\n",
    "\n",
    "zero_shot_df[\"keywords_from_icl\"] = zero_shot_df[\"keywords_from_icl\"].fillna(\"\").astype(str)\n",
    "zero_shot_df[\"top 5 keywords\"] = zero_shot_df[\"top 5 keywords\"].fillna(\"\").astype(str)\n",
    "few_shot_df[\"keywords_from_icl\"] = few_shot_df[\"keywords_from_icl\"].fillna(\"\").astype(str)\n",
    "few_shot_df[\"top 5 keywords\"] = few_shot_df[\"top 5 keywords\"].fillna(\"\").astype(str)\n",
    "\n",
    "zero_shot_icl_keywords = zero_shot_df[\"keywords_from_icl\"]\n",
    "zero_shot_roberta_keywords = zero_shot_df[\"top 5 keywords\"]\n",
    "few_shot_icl_keywords = few_shot_df[\"keywords_from_icl\"]\n",
    "few_shot_roberta_keywords = few_shot_df[\"top 5 keywords\"]\n",
    "\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1'])\n",
    "\n",
    "rouge_scores_zero_shot = []\n",
    "# roberta is Reference, icl is Candidate\n",
    "for roberta_keywords, icl_keywords in zip(zero_shot_roberta_keywords, zero_shot_icl_keywords):\n",
    "    scores = scorer.score(roberta_keywords, icl_keywords)\n",
    "    rouge_scores_zero_shot.append(scores)\n",
    "\n",
    "rouge_scores_few_shot = []\n",
    "# roberta is Reference, icl is Candidate\n",
    "for roberta_keywords, icl_keywords in zip(few_shot_roberta_keywords, few_shot_icl_keywords):\n",
    "    scores = scorer.score(roberta_keywords, icl_keywords)\n",
    "    rouge_scores_few_shot.append(scores)\n",
    "\n",
    "\n",
    "zero_shot_df[\"rouge_scores\"] = rouge_scores_zero_shot\n",
    "zero_shot_df[\"rouge_recall\"] = zero_shot_df[\"rouge_scores\"].apply(lambda x: x[\"rouge1\"].recall)\n",
    "zero_shot_df.to_csv(\"./keywords/zero_shot_rouge.csv\", index=False)\n",
    "\n",
    "few_shot_df[\"rouge_scores\"] = rouge_scores_few_shot\n",
    "few_shot_df[\"rouge_recall\"] = few_shot_df[\"rouge_scores\"].apply(lambda x: x[\"rouge1\"].recall)\n",
    "few_shot_df.to_csv(\"./keywords/few_shot_rouge.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
