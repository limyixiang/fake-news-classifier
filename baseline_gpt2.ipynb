{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT-2 Transformer Model for Sarcasm Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lfrostbyte/anaconda3/envs/CS4248/lib/python3.11/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/lfrostbyte/anaconda3/envs/CS4248/lib/python3.11/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import gensim\n",
    "import re\n",
    "import copy\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import GPT2Tokenizer, GPT2Model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from gensim.models import Word2Vec\n",
    "from tqdm import tqdm\n",
    "# https://colab.research.google.com/drive/1dMTdO5vxdVX0NA2Qe7AV9WGEy8ZH67Xn?usp=sharing#scrollTo=afcc233b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/lfrostbyte/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/lfrostbyte/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/lfrostbyte/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download NLTK resources\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72\n",
      "72\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_json(path_or_buf=\"./Sarcasm_Headlines_Dataset.json\", lines=True)\n",
    "train_df.rename(columns={\"headline\": \"text\", \"is_sarcastic\": \"label\"}, inplace=True)\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()  # Lowercasing\n",
    "    text = re.sub(r'\\W', ' ', text)  # Remove non-alphanumeric characters\n",
    "    tokens = word_tokenize(text)  # Tokenization\n",
    "    tokens = [word for word in tokens if word.isalpha()]  # Remove numbers and punctuation\n",
    "    tokens = [word for word in tokens if word not in stopwords.words('english')]  # Stopword removal\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]  # Lemmatization\n",
    "    \n",
    "    return tokens if tokens else None\n",
    "\n",
    "# # For convenience\n",
    "train_df = train_df.head(100)\n",
    "\n",
    "# Apply preprocessing\n",
    "# train_df['processed_text'] = train_df['text'].apply(preprocess_text)\n",
    "# train_df = train_df.dropna(subset=['processed_text']) # After preprocessing, there will be some rows that are empty, delete these rows\n",
    "\n",
    "\n",
    "# Split into train, test, validation (80% train, 20% validation from train)\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "    train_df['text'], train_df['label'], test_size=0.2, random_state=42)\n",
    "\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    train_texts, train_labels, test_size=0.1, random_state=42) # Ideally test_size should be 1/8 because 0.8 * 1/8 = 0.1 so its 10% for validation, but 0.08 is also fine.\n",
    "\n",
    "print(len(train_texts))\n",
    "print(len(train_labels))\n",
    "\n",
    "train_texts = train_texts.reset_index(drop=True)\n",
    "train_labels = train_labels.reset_index(drop=True)\n",
    "val_texts = val_texts.reset_index(drop=True)\n",
    "val_labels = val_labels.reset_index(drop=True)\n",
    "test_texts = test_texts.reset_index(drop=True)\n",
    "test_labels = test_labels.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            ryan lochte apologizes for behavior in rio\n",
       "1     ex-boyfriend just thought he'd check in and th...\n",
       "2     5 questions i wish younger people would stop a...\n",
       "3     selig counted money while baseball lost the ne...\n",
       "4     mom starting to fear son's web series closest ...\n",
       "                            ...                        \n",
       "67                    monster undeterred by night-light\n",
       "68    report: john grisham slowly but surely climbin...\n",
       "69    the vicious knot of syria, the untangling proc...\n",
       "70           look: world cup star attacked by giant bug\n",
       "71    scott used to stop breathing nearly 40 times a...\n",
       "Name: text, Length: 72, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPT2SequenceClassifier(torch.nn.Module):\n",
    "    def __init__(self, hidden_size: int, num_classes: int, max_seq_len: int):\n",
    "        super(GPT2SequenceClassifier,self).__init__()\n",
    "        self.frontLayer = GPT2Model.from_pretrained('gpt2')\n",
    "        trf_out_size = hidden_size * max_seq_len\n",
    "        self.fc = torch.nn.Linear(in_features=trf_out_size, out_features=num_classes)\n",
    "\n",
    "    def forward(self, input_id, mask):\n",
    "        \"\"\"\n",
    "        Args: input_id: encoded input of ids that were sent\n",
    "        \"\"\"\n",
    "        gpt_out, _ = self.frontLayer(input_ids=input_id, attention_mask=mask, return_dict=False)\n",
    "        batch_size = gpt_out.shape[0]\n",
    "        linear_output = self.fc(gpt_out.view(batch_size, -1))\n",
    "        return linear_output\n",
    "\n",
    "class SarcasmDataset(Dataset):\n",
    "    def __init__(self, headlines, labels, tokenizer, max_length=50):\n",
    "        self.headlines = headlines\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def classes(self):\n",
    "        return self.labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.headlines)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        processed_headline = self.headlines[idx]\n",
    "        # processed_headline = \" \".join(self.headlines[idx])\n",
    "        encoded_data = self.tokenizer(processed_headline, padding='max_length', max_length=self.max_length, truncation=True, return_tensors=\"pt\")\n",
    "        return encoded_data, self.labels[idx]\n",
    "    \n",
    "def load_model(path, hidden_size, max_seq_len):\n",
    "    model = GPT2SequenceClassifier(hidden_size=hidden_size, num_classes=2, max_seq_len=max_seq_len)\n",
    "    model.load_state_dict(torch.load(path))\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def train(model, trainData, valData, lr, max_epochs, early_stop_tol):\n",
    "    trainLoader = DataLoader(trainData, batch_size=16, shuffle=True)\n",
    "    valLoader = DataLoader(valData, batch_size=16, shuffle=True)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    if use_cuda:\n",
    "        model = model.cuda()\n",
    "        criterion = criterion.cuda()\n",
    "\n",
    "    did_not_improve_count = 0\n",
    "    best_val_score = 0\n",
    "    best_epoch = 0\n",
    "    best_state_dict = None\n",
    "    model.train()\n",
    "    \n",
    "    for epoch_num in range(max_epochs):\n",
    "        # total_acc_train = 0\n",
    "        total_loss_train = 0\n",
    "        train_predictions = []\n",
    "        train_labels = []\n",
    "        for encoded_data, train_label in tqdm(trainLoader):\n",
    "            train_label = train_label.to(device)\n",
    "            mask = encoded_data['attention_mask'].to(device)\n",
    "            input_id = encoded_data[\"input_ids\"].squeeze(1).to(device)            \n",
    "\n",
    "            model.zero_grad()\n",
    "\n",
    "            output = model(input_id, mask)\n",
    "\n",
    "            batch_loss = criterion(output, train_label)\n",
    "            total_loss_train += batch_loss.item()\n",
    "\n",
    "            # acc = (output.argmax(dim=1) == train_label).sum().item()\n",
    "            # total_acc_train += acc\n",
    "\n",
    "            # add original labels\n",
    "            train_labels += train_label.cpu().numpy().flatten().tolist()\n",
    "            # get predicitons to list\n",
    "            train_predictions += output.argmax(dim=1).cpu().numpy().flatten().tolist()\n",
    "\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        # total_acc_val = 0\n",
    "        total_loss_val = 0\n",
    "        val_predictions = []\n",
    "        val_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for val_input, val_label in valLoader:\n",
    "                val_label = val_label.to(device)\n",
    "                mask = val_input['attention_mask'].to(device)\n",
    "                input_id = val_input['input_ids'].squeeze(1).to(device)\n",
    "                \n",
    "                output = model(input_id, mask)\n",
    "                \n",
    "                batch_loss = criterion(output, val_label)\n",
    "                total_loss_val += batch_loss.item()\n",
    "                \n",
    "                # acc = (output.argmax(dim=1)==val_label).sum().item()\n",
    "                # total_acc_val += acc\n",
    "                # add original labels\n",
    "                val_labels += val_label.cpu().numpy().flatten().tolist()\n",
    "                # get predicitons to list\n",
    "                val_predictions += output.argmax(dim=1).cpu().numpy().flatten().tolist()\n",
    "            \n",
    "\n",
    "        # total_acc_val = total_acc_val/len(valData)\n",
    "        f1_train = f1_score(train_labels, train_predictions, average='macro')\n",
    "        f1_val = f1_score(val_labels, val_predictions, average='macro')\n",
    "\n",
    "        if f1_val > (best_val_score + early_stop_tol):\n",
    "            best_val_score = f1_val\n",
    "            did_not_improve_count = 0\n",
    "            best_epoch = epoch_num\n",
    "            best_state_dict = copy.deepcopy(model.state_dict())\n",
    "            print(f\"Saving new best val acc {best_val_score}\")\n",
    "            torch.save(best_state_dict, f\"./gpt2-classifier-model-lr{lr}-iter{best_epoch+1}-tol{early_stop_tol}.pt\")\n",
    "        else:\n",
    "            did_not_improve_count += 1\n",
    "\n",
    "        if did_not_improve_count >= 10:\n",
    "            break\n",
    "\n",
    "        print(\n",
    "            f\"Epochs: {epoch_num + 1} | Train Loss: {total_loss_train/len(trainData): .3f} \\\n",
    "            | Train Score: {f1_train: .3f} \\\n",
    "             | Val Loss: {total_loss_val / len(valData): .3f} \\\n",
    "             | Val Score: {f1_val: .3f}\")\n",
    "        \n",
    "def evaluate(model, testLoader, length):\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    if use_cuda:\n",
    "        model = model.cuda()\n",
    "\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "\n",
    "    total_acc_test = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for test_input, test_label in testLoader:\n",
    "            test_label = test_label.to(device)\n",
    "            mask = test_input['attention_mask'].to(device)\n",
    "            input_id = test_input['input_ids'].squeeze(1).to(device)\n",
    "            \n",
    "            output = model(input_id, mask)\n",
    "                        \n",
    "            acc = (output.argmax(dim=1)==test_label).sum().item()\n",
    "            total_acc_test += acc\n",
    "\n",
    "            # add original labels\n",
    "            true_labels += test_label.cpu().numpy().flatten().tolist()\n",
    "            # get predictions to list\n",
    "            predictions += output.argmax(dim=1).cpu().numpy().flatten().tolist()\n",
    "    test_score = f1_score(true_labels, predictions, average='macro')\n",
    "    test_acc = total_acc_test / length\n",
    "    print(f'Test Accuracy: {test_acc: .3f}, F1 Score: {test_score: .3f}')\n",
    "    return true_labels, predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lfrostbyte/anaconda3/envs/CS4248/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "tokenizer.padding_side = \"left\"\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "seq_len = 128\n",
    "hidden_size = 768\n",
    "val_tol = 0.01\n",
    "lr = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPT2SequenceClassifier(hidden_size=hidden_size, num_classes=2, max_seq_len=seq_len)\n",
    "trainData = SarcasmDataset(headlines=train_texts, labels=train_labels, tokenizer=tokenizer, max_length=seq_len)\n",
    "valData = SarcasmDataset(headlines=val_texts, labels=val_labels, tokenizer=tokenizer, max_length=seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:01<00:00,  3.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best val acc 0.5\n",
      "Epochs: 1 | Train Loss:  0.182             | Train Score:  0.360              | Val Loss:  0.117              | Val Score:  0.500              | Best Val Score:  0.500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:01<00:00,  4.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 2 | Train Loss:  0.051             | Train Score:  0.514              | Val Loss:  0.145              | Val Score:  0.467              | Best Val Score:  0.500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:01<00:00,  4.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 3 | Train Loss:  0.057             | Train Score:  0.529              | Val Loss:  0.086              | Val Score:  0.500              | Best Val Score:  0.500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:01<00:00,  4.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best val acc 0.75\n",
      "Epochs: 4 | Train Loss:  0.049             | Train Score:  0.612              | Val Loss:  0.079              | Val Score:  0.750              | Best Val Score:  0.750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:01<00:00,  4.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 5 | Train Loss:  0.071             | Train Score:  0.500              | Val Loss:  0.137              | Val Score:  0.273              | Best Val Score:  0.750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:01<00:00,  4.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 6 | Train Loss:  0.048             | Train Score:  0.610              | Val Loss:  0.128              | Val Score:  0.273              | Best Val Score:  0.750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:01<00:00,  4.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 7 | Train Loss:  0.040             | Train Score:  0.663              | Val Loss:  0.098              | Val Score:  0.500              | Best Val Score:  0.750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:01<00:00,  4.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 8 | Train Loss:  0.033             | Train Score:  0.743              | Val Loss:  0.086              | Val Score:  0.365              | Best Val Score:  0.750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:01<00:00,  4.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 9 | Train Loss:  0.033             | Train Score:  0.776              | Val Loss:  0.135              | Val Score:  0.273              | Best Val Score:  0.750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:01<00:00,  4.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 10 | Train Loss:  0.024             | Train Score:  0.845              | Val Loss:  0.141              | Val Score:  0.333              | Best Val Score:  0.750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:01<00:00,  4.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 11 | Train Loss:  0.019             | Train Score:  0.871              | Val Loss:  0.169              | Val Score:  0.365              | Best Val Score:  0.750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:01<00:00,  4.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 12 | Train Loss:  0.016             | Train Score:  0.928              | Val Loss:  0.139              | Val Score:  0.500              | Best Val Score:  0.750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:01<00:00,  4.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 13 | Train Loss:  0.017             | Train Score:  0.861              | Val Loss:  0.520              | Val Score:  0.273              | Best Val Score:  0.750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:01<00:00,  4.69it/s]\n"
     ]
    }
   ],
   "source": [
    "train(model, trainData, valData, lr, 500, val_tol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lfrostbyte/anaconda3/envs/CS4248/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.700, F1 Score:  0.600\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "testData = SarcasmDataset(headlines=test_texts, labels=test_labels, tokenizer=tokenizer, max_length=seq_len)\n",
    "testLoader = DataLoader(testData, batch_size=16, shuffle=True)\n",
    "\n",
    "model = load_model(\"./gpt2-classifier-model-lr1e-05-iter3-tol0.05-preprocessing.pt\", hidden_size=768, max_seq_len=seq_len)\n",
    "\n",
    "evaluate(model, testLoader, len(testData))\n",
    "\n",
    "print(len(testData))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CS4248",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
