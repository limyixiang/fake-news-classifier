{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting accelerate\n",
      "  Downloading accelerate-1.6.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in c:\\repos\\cs3264 project\\.venv\\lib\\site-packages (from accelerate) (2.2.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\repos\\cs3264 project\\.venv\\lib\\site-packages (from accelerate) (24.2)\n",
      "Requirement already satisfied: psutil in c:\\repos\\cs3264 project\\.venv\\lib\\site-packages (from accelerate) (7.0.0)\n",
      "Requirement already satisfied: pyyaml in c:\\repos\\cs3264 project\\.venv\\lib\\site-packages (from accelerate) (6.0.2)\n",
      "Requirement already satisfied: torch>=2.0.0 in c:\\repos\\cs3264 project\\.venv\\lib\\site-packages (from accelerate) (2.6.0+cu118)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in c:\\repos\\cs3264 project\\.venv\\lib\\site-packages (from accelerate) (0.30.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\repos\\cs3264 project\\.venv\\lib\\site-packages (from accelerate) (0.5.3)\n",
      "Requirement already satisfied: filelock in c:\\repos\\cs3264 project\\.venv\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\repos\\cs3264 project\\.venv\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (2024.12.0)\n",
      "Requirement already satisfied: requests in c:\\repos\\cs3264 project\\.venv\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\repos\\cs3264 project\\.venv\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\repos\\cs3264 project\\.venv\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (4.13.1)\n",
      "Requirement already satisfied: networkx in c:\\repos\\cs3264 project\\.venv\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\repos\\cs3264 project\\.venv\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.1.4)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\repos\\cs3264 project\\.venv\\lib\\site-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\repos\\cs3264 project\\.venv\\lib\\site-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\repos\\cs3264 project\\.venv\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub>=0.21.0->accelerate) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\repos\\cs3264 project\\.venv\\lib\\site-packages (from jinja2->torch>=2.0.0->accelerate) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\repos\\cs3264 project\\.venv\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\repos\\cs3264 project\\.venv\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\repos\\cs3264 project\\.venv\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\repos\\cs3264 project\\.venv\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2025.1.31)\n",
      "Downloading accelerate-1.6.0-py3-none-any.whl (354 kB)\n",
      "Installing collected packages: accelerate\n",
      "Successfully installed accelerate-1.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Collecting torch\n",
      "  Using cached https://download.pytorch.org/whl/cu118/torch-2.6.0%2Bcu118-cp311-cp311-win_amd64.whl.metadata (28 kB)\n",
      "Collecting torchvision\n",
      "  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.21.0%2Bcu118-cp311-cp311-win_amd64.whl.metadata (6.3 kB)\n",
      "Collecting torchaudio\n",
      "  Using cached https://download.pytorch.org/whl/cu118/torchaudio-2.6.0%2Bcu118-cp311-cp311-win_amd64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: filelock in c:\\repos\\cs3264 project\\.venv\\lib\\site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\repos\\cs3264 project\\.venv\\lib\\site-packages (from torch) (4.13.1)\n",
      "Collecting networkx (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/networkx-3.3-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting jinja2 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/Jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: fsspec in c:\\repos\\cs3264 project\\.venv\\lib\\site-packages (from torch) (2024.12.0)\n",
      "Collecting sympy==1.13.1 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "     ---------------------------------------- 0.0/6.2 MB ? eta -:--:--\n",
      "     ---------------------------------------- 6.2/6.2 MB 95.6 MB/s eta 0:00:00\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch)\n",
      "  Using cached https://download.pytorch.org/whl/mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Requirement already satisfied: numpy in c:\\repos\\cs3264 project\\.venv\\lib\\site-packages (from torchvision) (2.2.4)\n",
      "Collecting pillow!=8.3.*,>=5.3.0 (from torchvision)\n",
      "  Downloading https://download.pytorch.org/whl/pillow-11.0.0-cp311-cp311-win_amd64.whl.metadata (9.3 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch)\n",
      "  Downloading https://download.pytorch.org/whl/MarkupSafe-2.1.5-cp311-cp311-win_amd64.whl (17 kB)\n",
      "Using cached https://download.pytorch.org/whl/cu118/torch-2.6.0%2Bcu118-cp311-cp311-win_amd64.whl (2728.9 MB)\n",
      "Downloading https://download.pytorch.org/whl/cu118/torchvision-0.21.0%2Bcu118-cp311-cp311-win_amd64.whl (5.3 MB)\n",
      "   ---------------------------------------- 0.0/5.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 5.3/5.3 MB 81.3 MB/s eta 0:00:00\n",
      "Using cached https://download.pytorch.org/whl/cu118/torchaudio-2.6.0%2Bcu118-cp311-cp311-win_amd64.whl (4.1 MB)\n",
      "Downloading https://download.pytorch.org/whl/pillow-11.0.0-cp311-cp311-win_amd64.whl (2.6 MB)\n",
      "   ---------------------------------------- 0.0/2.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.6/2.6 MB 74.3 MB/s eta 0:00:00\n",
      "Downloading https://download.pytorch.org/whl/Jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
      "Downloading https://download.pytorch.org/whl/networkx-3.3-py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.7/1.7 MB 96.0 MB/s eta 0:00:00\n",
      "Installing collected packages: mpmath, sympy, pillow, networkx, MarkupSafe, jinja2, torch, torchvision, torchaudio\n",
      "Successfully installed MarkupSafe-2.1.5 jinja2-3.1.4 mpmath-1.3.0 networkx-3.3 pillow-11.0.0 sympy-1.13.1 torch-2.6.0+cu118 torchaudio-2.6.0+cu118 torchvision-0.21.0+cu118\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\repos\\CS3264 Project\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.51.1\n",
      "2.6.0+cu118\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "import torch\n",
    "\n",
    "print(transformers.__version__)\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer\n",
    "from datasets import load_dataset\n",
    "from collections import Counter\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.2, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.2, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model_path = \"./bert/without_icl/roberta_new\"\n",
    "model_path = \"./weighted_loss/models/bert_fake_news\"\n",
    "# model_path = \"roberta-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "print(torch.cuda.is_available())\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "model.eval() # Set model to evaluation mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 2296/2296 [00:00<00:00, 6635.84 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before label preprocessing: Labels = Counter({1: 660, 3: 371, 2: 360, 4: 343, 0: 303, 5: 259})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 2296/2296 [00:00<00:00, 30056.47 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After label preprocessing: Labels = Counter({1: 1694, 0: 602})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = \"chengxuphd/liar2\"\n",
    "dataset = load_dataset(dataset)\n",
    "test_dataset = dataset[\"test\"]\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    combined_input = [\n",
    "        \"Subject: \" + (subject if subject is not None else \"\") + \n",
    "        \"; Speaker: \" + (speaker if speaker is not None else \"\") + \n",
    "        \"; Speaker Description: \" + (speaker_description if speaker_description is not None else \"\") + \n",
    "        \"; State: \" + (state_info if state_info is not None else \"\") + \n",
    "        \"; Context: \" + (context if context is not None else \"\") + \n",
    "        \"; Statement: \" + (statement if statement is not None else \"\")\n",
    "        for subject, speaker, speaker_description, state_info, context, statement in zip(\n",
    "            examples[\"subject\"],\n",
    "            examples[\"speaker\"],\n",
    "            examples[\"speaker_description\"],\n",
    "            examples[\"state_info\"],\n",
    "            examples[\"context\"],\n",
    "            examples[\"statement\"]\n",
    "        )\n",
    "    ]\n",
    "    return tokenizer(combined_input, padding=\"max_length\", truncation=True)\n",
    "\n",
    "test_dataset = test_dataset.map(preprocess_function, batched=True)\n",
    "test_dataset.set_format(\"torch\")\n",
    "\n",
    "label_to_binary = {\n",
    "    # True = FAKE; False = REAL\n",
    "    0: True,\n",
    "    1: True,\n",
    "    2: True,\n",
    "    3: True, # Changed to FAKE\n",
    "    4: False,\n",
    "    5: False\n",
    "}\n",
    "\n",
    "original_label_counts = Counter(test_dataset[\"label\"].tolist())\n",
    "print(\"Before label preprocessing: Labels =\", original_label_counts)\n",
    "\n",
    "test_dataset = test_dataset.map(\n",
    "    lambda examples: {\"label\": [label_to_binary[int(label)] for label in examples[\"label\"]]},\n",
    "    batched=True\n",
    ")\n",
    "\n",
    "binary_label_counts = Counter(test_dataset[\"label\"].tolist())\n",
    "print(\"After label preprocessing: Labels =\", binary_label_counts)\n",
    "\n",
    "# assert (\n",
    "#     original_label_counts[0] + original_label_counts[1] + original_label_counts[2]\n",
    "#     == binary_label_counts[True]\n",
    "# ), \"Sum of original labels 0, 1, 2 does not match new label 0 (Fake).\"\n",
    "\n",
    "# assert (\n",
    "#     original_label_counts[3] + original_label_counts[4] + original_label_counts[5]\n",
    "#     == binary_label_counts[False]\n",
    "# ), \"Sum of original labels 3, 4, 5 does not match new label 1 (Real).\"\n",
    "\n",
    "# print(\"Assertions passed: Label mapping is correct.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average=\"binary\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        \"accuracy\": acc,\n",
    "        \"f1\": f1,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Metrics:\n",
      "test_loss: 0.5835\n",
      "test_model_preparation_time: 0.0010\n",
      "test_accuracy: 0.6999\n",
      "test_f1: 0.7660\n",
      "test_precision: 0.9017\n",
      "test_recall: 0.6659\n",
      "test_runtime: 33.2061\n",
      "test_samples_per_second: 69.1440\n",
      "test_steps_per_second: 8.6430\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "test_results = trainer.predict(test_dataset)\n",
    "\n",
    "predictions = test_results.predictions.argmax(-1)  # Convert logits to class predictions\n",
    "metrics = test_results.metrics  # Contains accuracy, F1, precision, recall, etc.\n",
    "\n",
    "print(\"Test Metrics:\")\n",
    "for key, value in metrics.items():\n",
    "    print(f\"{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Oversampling with Weighted Loss Function Results\n",
    "\n",
    "| Metric                        | Roberta   | Bert_fake_news    |\n",
    "|-------------------------------|-----------|-------------------|\n",
    "| Test Loss                     | 0.5699    | 0.5835            |\n",
    "| Test Model Preparation Time   | 0.0008    | 0.0010            |\n",
    "| Test Accuracy                 | 0.7003    | 0.6999            |\n",
    "| Test F1 Score                 | 0.7682    | 0.7660            |\n",
    "| Test Precision                | 0.8948    | 0.9017            |\n",
    "| Test Recall                   | 0.6730    | 0.6659            |\n",
    "| Test Runtime (seconds)        | 34.2017   | 33.2061           |\n",
    "| Test Samples/Second           | 67.1310   | 69.1440           |\n",
    "| Test Steps/Second             | 8.3910    | 8.6430            |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Oversampling Methods (using baseline roberta)\n",
    "\n",
    "| Metric                        | Regular | Weighted_loss   |\n",
    "|-------------------------------|---------|-----------------|\n",
    "| Test Loss                     | 0.6739  | 0.5699          |\n",
    "| Test Model Preparation Time   | 0.0020  | 0.0008          |\n",
    "| Test Accuracy                 | 0.6995  | 0.7003          |\n",
    "| Test F1 Score                 | 0.7702  | 0.7682          |\n",
    "| Test Precision                | 0.8838  | 0.8948          |\n",
    "| Test Recall                   | 0.6824  | 0.6730          |\n",
    "| Test Runtime (seconds)        | 37.4584 | 34.2017         |\n",
    "| Test Samples/Second           | 61.2950 | 67.1310         |\n",
    "| Test Steps/Second             | 7.6620  | 8.3910          |\n",
    "\n",
    "Abnormal runtime on the weighted_loss model because I was running the test on my macbook without GPU usage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AFTER LABEL SWAP\n",
    "\n",
    "##### WITHOUT IN-CONTEXT LEARNING JUSTIFICATION\n",
    "\n",
    "| Metric                                | roberta   | bert_fake_news    | augmented_normal  | normal_augmented  |\n",
    "|---------------------------------------|-----------|-------------------|-------------------|-------------------|\n",
    "| Test Loss                             | 0.5207    | 0.5508            | 0.5444            | 0.5291            |\n",
    "| Test Model Preparation Time (seconds) | 0.0020    | 0.0020            | 0.0020            | 0.0010            |\n",
    "| Test Accuracy                         | 0.7295    | 0.7317            | 0.7326            | 0.7348            |\n",
    "| Test F1 Score                         | 0.7663    | 0.7548            | 0.7607            | 0.7505            |\n",
    "| Test Precision                        | 0.7631    | 0.7973            | 0.7852            | 0.8193            |\n",
    "| Test Recall                           | 0.7695    | 0.7166            | 0.7377            | 0.6924            |\n",
    "| Test Runtime (seconds)                | 38.4320   | 36.0601           | 34.2745           | 33.9310           |\n",
    "| Test Samples/Second                   | 59.7420   | 63.6720           | 66.9880           | 67.6670           |\n",
    "| Test Steps/Second                     | 7.4680    | 7.9590            | 8.3740            | 8.4580            |\n",
    "\n",
    "Since roberta provided a better recall score, we shall compare data augmentation on the roberta model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BEFORE LABEL SWAP\n",
    "\n",
    "| Metric                                | roberta   | augmented_normal  | normal_augmented  | justification | bert_fake_news    |\n",
    "|---------------------------------------|-----------|-------------------|-------------------|---------------|-------------------|\n",
    "| Test Loss                             | 0.5339    | 0.6042            | 0.5393            | 0.7983        | 0.5354            |\n",
    "| Test Model Preparation Time (seconds) | 0.0010    | 0.0020            | 0.0020            | 0.0010        | 0.0020            |\n",
    "| Test Accuracy                         | 0.7395    | 0.7352            | 0.7260            | 0.6760        | 0.7317            |\n",
    "| Test F1 Score                         | 0.7051    | 0.7214            | 0.7137            | 0.6958        | 0.7100            |\n",
    "| Test Precision                        | 0.6777    | 0.6510            | 0.6405            | 0.5777        | 0.6551            |\n",
    "| Test Recall                           | 0.7348    | 0.8088            | 0.8058            | 0.8746        | 0.7749            |\n",
    "| Test Runtime (seconds)                | 33.5466   | 33.379            | 33.718            | 33.415        | 33.5630           |\n",
    "| Test Samples/Second                   | 68.4420   | 68.785            | 68.094            | 68.710        | 68.4090           |\n",
    "| Test Steps/Second                     | 8.5550    | 8.5980            | 8.5120            | 8.5890        | 8.5510            |\n",
    "\n",
    "Roberta seems to be the best model out of all 5."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
