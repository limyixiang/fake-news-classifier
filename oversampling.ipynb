{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b4f5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Example dataset\n",
    "df = pd.DataFrame({\n",
    "    'feature1': [1, 2, 3, 4, 5, 6],\n",
    "    'label':    [0, 0, 0, 1, 1, 1]\n",
    "})\n",
    "\n",
    "# Calculate class counts and assign weights as the inverse of the frequency\n",
    "class_counts = df['label'].value_counts()\n",
    "df['weight'] = df['label'].apply(lambda x: 1.0 / class_counts[x])\n",
    "\n",
    "# Normalize weights to sum to 1 (optional but recommended)\n",
    "weights = df['weight'] / df['weight'].sum()\n",
    "\n",
    "# Define the number of samples for the oversampled dataset.\n",
    "# For instance, aim to have the same total samples as twice the original dataset size.\n",
    "n_samples = len(df) * 2\n",
    "\n",
    "# Perform weighted sampling with replacement\n",
    "sampled_indices = np.random.choice(df.index, size=n_samples, replace=True, p=weights)\n",
    "oversampled_df = df.loc[sampled_indices].reset_index(drop=True)\n",
    "\n",
    "print(oversampled_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63c26c94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original train class counts: label\n",
      "1    5284\n",
      "3    2967\n",
      "2    2882\n",
      "4    2743\n",
      "0    2425\n",
      "5    2068\n",
      "Name: count, dtype: int64\n",
      "After preprocessing, train class counts: label\n",
      "1    13558\n",
      "0     4811\n",
      "Name: count, dtype: int64\n",
      "After oversampling, train class counts: label\n",
      "1    13621\n",
      "0    13495\n",
      "Name: count, dtype: int64\n",
      "After oversampling, val class counts: label\n",
      "0    1727\n",
      "1    1665\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "\n",
    "original_dataset = load_dataset(\"chengxuphd/liar2\")\n",
    "train_df = original_dataset[\"train\"].to_pandas()\n",
    "val_df = original_dataset[\"validation\"].to_pandas()\n",
    "\n",
    "# print(train_df.columns)\n",
    "\n",
    "train_class_counts = train_df['label'].value_counts()\n",
    "val_class_counts = val_df['label'].value_counts()\n",
    "print(\"Original train class counts:\", train_class_counts)\n",
    "\n",
    "# 0, 1, 2, 3 means FAKE and 4, 5 means REAL\n",
    "train_df['label'] = train_df['label'].apply(lambda x: 1 if x in [0, 1, 2, 3] else 0)\n",
    "val_df['label'] = val_df['label'].apply(lambda x: 1 if x in [0, 1, 2, 3] else 0)\n",
    "train_class_counts = train_df['label'].value_counts()\n",
    "val_class_counts = val_df['label'].value_counts()\n",
    "print(\"After preprocessing, train class counts:\", train_class_counts)\n",
    "\n",
    "# Add weights to the 2 classes\n",
    "train_df['weight'] = train_df['label'].apply(lambda x: 1.0 / train_class_counts[x])\n",
    "val_df['weight'] = val_df['label'].apply(lambda x: 1.0 / val_class_counts[x])\n",
    "# print(train_df['weight'])\n",
    "\n",
    "# Normalize weights\n",
    "train_weights = train_df['weight'] / train_df['weight'].sum()\n",
    "val_weights = val_df['weight'] / val_df['weight'].sum()\n",
    "# print(train_weights)\n",
    "\n",
    "n_train_samples = train_class_counts.max() * 2\n",
    "n_val_samples = val_class_counts.max() * 2\n",
    "\n",
    "sampled_train_indices = np.random.choice(train_df.index, size=n_train_samples, replace=True, p=train_weights)\n",
    "sampled_val_indices = np.random.choice(val_df.index, size=n_val_samples, replace=True, p=val_weights)\n",
    "\n",
    "oversampled_train_df = train_df.loc[sampled_train_indices].reset_index(drop=True)\n",
    "oversampled_val_df = val_df.loc[sampled_val_indices].reset_index(drop=True)\n",
    "oversampled_train_class_counts = oversampled_train_df['label'].value_counts()\n",
    "oversampled_val_class_counts = oversampled_val_df['label'].value_counts()\n",
    "\n",
    "print(\"After oversampling, train class counts:\", oversampled_train_class_counts)\n",
    "print(\"After oversampling, val class counts:\", oversampled_val_class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60302b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09b775d0732649c2bd5f91f5e2d787c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/27116 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9858047ec0c49699ee762b28f599360",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/3392 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "train_dataset = Dataset.from_pandas(oversampled_train_df)\n",
    "val_dataset = Dataset.from_pandas(oversampled_val_df)\n",
    "\n",
    "train_dataset.save_to_disk(\"./bert/oversampled_datasets/train\")\n",
    "val_dataset.save_to_disk(\"./bert/oversampled_datasets/validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96dc0c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test class counts: label\n",
      "1    1694\n",
      "0     602\n",
      "Name: count, dtype: int64\n",
      "Test class counts: label\n",
      "0    602\n",
      "1    602\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\limyi\\AppData\\Local\\Temp\\ipykernel_13908\\3268896807.py:7: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  test_df = test_df.groupby('label').apply(lambda x: x.sample(n=min_class_count, random_state=42)).reset_index(drop=True)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab1fb7bb7f574c8e90ab814eaf35ef81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/1204 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_df = original_dataset[\"test\"].to_pandas()\n",
    "test_df['label'] = test_df['label'].apply(lambda x: 1 if x in [0, 1, 2, 3] else 0)\n",
    "test_class_counts = test_df['label'].value_counts()\n",
    "print(\"Test class counts:\", test_class_counts)\n",
    "\n",
    "min_class_count = test_class_counts.min()\n",
    "test_df = test_df.groupby('label').apply(lambda x: x.sample(n=min_class_count, random_state=42)).reset_index(drop=True)\n",
    "test_class_counts = test_df['label'].value_counts()\n",
    "print(\"Test class counts:\", test_class_counts)\n",
    "\n",
    "test_dataset = Dataset.from_pandas(test_df)\n",
    "test_dataset.save_to_disk(\"./bert/oversampled_datasets/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e7b5efd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "929b6f41c3f047b3903c92d9c255c73f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating CSV from Arrow format:   0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1248103"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "test_dataset = load_from_disk(\"./bert/oversampled_datasets/test\")\n",
    "test_dataset.to_csv(\"delete_later.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bec2519",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
